Multimodality Chat Application (Powered by Google Gemini API)
Project Overview

Multimodality Chat is an advanced AI-powered Streamlit application built using the Google Gemini API.
It supports text, image, document, audio, video, and YouTube-based interactions in a single unified chat interface.

All user and AI conversations are stored persistently in MongoDB, enabling chat history tracking and future analysis.

This project showcases real-world usage of Google Gemini multimodal models, backend database integration, and scalable Python application development.

ğŸš€Key Features

ğŸ’¬ Conversational AI using Google Gemini API

ğŸ–¼ Image understanding with Gemini Vision

ğŸ“„ PDF / DOCX / TXT document summarization

â–¶ï¸ YouTube video transcript summarization

ğŸ§ Audio upload â†’ Speech-to-Text (Whisper)

ğŸ¥ Video upload â†’ AI-based video summarization

ğŸ”Š Text-to-Speech audio responses

ğŸ—‚ Chat export as PDF

ğŸ—„ MongoDB chat history storage

ğŸ¨ Light / Dark theme toggle

ğŸ‘¤ User & AI avatars with styled chat bubbles

ğŸ› ï¸ Tech Stack
ğŸ”¹ Programming & Framework

Python

Streamlit

ğŸ”¹ AI & APIs

Google Gemini API

gemini-1.5-flash

gemini-2.0-flash-lite

Phi Agent Framework

Whisper (Speech-to-Text)

gTTS (Text-to-Speech)

ğŸ”¹ File & Media Processing

PIL (Images)

PyPDF2 (PDF)

python-docx (DOCX)

youtube-transcript-api

pydub (Audio)

ğŸ”¹ Database

MongoDB

PyMongo

ğŸ—„ï¸ Database Design (MongoDB)

Database Name

multimodal_chat_db


Collection

chat_responses


Stored Fields

role (user / assistant)

text (message content)

timestamp (message time)

Install Dependencies
pip install -r requirements.txt

Configure Google Gemini API & MongoDB

Create a .env file:

GOOGLE_API_KEY=your_google_gemini_api_key
MONGO_URI=your_mongodb_connection_string

Run Application
streamlit run app.py

ğŸ“‚ Project Structure
Multimodality-Chat/
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
